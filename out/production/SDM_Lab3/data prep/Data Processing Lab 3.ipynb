{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6ec5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from lorem_text import lorem\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24c21672",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('article.csv', sep=';')\n",
    "proceeding = pd.read_csv('proceeding_papers.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f47d61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reviews(x):\n",
    "    rev = x.split('|')\n",
    "    reviews = ''\n",
    "    for r in rev:\n",
    "        if len(reviews) > 0:\n",
    "            reviews += '|'\n",
    "        reviews += lorem.words(10)\n",
    "    return reviews\n",
    "\n",
    "def generate_decisions(x):\n",
    "    rev = x.split('|')\n",
    "    decisions = ''\n",
    "    for r in rev:\n",
    "        if len(decisions) > 0:\n",
    "            decisions += '|'\n",
    "        decisions += 'Accepted'\n",
    "    return decisions\n",
    "\n",
    "def generate_decisionIDs(art, rev):\n",
    "    reviewers = rev.split('|')\n",
    "    IDs = ''\n",
    "    for i, r in enumerate(reviewers):\n",
    "        if len(IDs) > 0:\n",
    "            IDs += '|'\n",
    "        IDs += f\"review{art}_{i}\" \n",
    "    return IDs\n",
    "\n",
    "def remove_non_alphabetic_characters(x):\n",
    "    return re.sub(r'[^a-zA-Z|]', '', x)\n",
    "\n",
    "def replace_capitals(x):\n",
    "    return x.lower()\n",
    "\n",
    "def remove_space(x):\n",
    "    return x.replace(' ','')\n",
    "\n",
    "def replace_null_authors(x):\n",
    "    if type(x) == float:\n",
    "        return \"TheRiddler\"\n",
    "    else: return x\n",
    "    \n",
    "def replace_null_topics(x):\n",
    "    if type(x) == float:\n",
    "        return \"Nothing\"\n",
    "    else: return x\n",
    "\n",
    "def clean_instances(x):\n",
    "    x = remove_non_alphabetic_characters(x)\n",
    "    x = remove_space(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16578eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "proceeding = proceeding.rename(columns = {'booktitle': 'conference',\n",
    "                                          'inproctitle': 'articleTitle', \n",
    "                                          'proctitle': 'conferenceTitle',\n",
    "                                          'keywords': 'topic',\n",
    "                                          'inprocee': 'doi',\n",
    "                                          'proceedings': 'conferenceID',\n",
    "                                          'inproceedings': 'articleID'\n",
    "                                         })\n",
    "\n",
    "\n",
    "\n",
    "proceeding['conferenceID'] = proceeding.groupby(by=['conference', 'procmdate', 'conferenceTitle']).ngroup().add(1)\n",
    "confID = proceeding['conferenceID'].unique()\n",
    "authors = proceeding['author'].unique()\n",
    "\n",
    "a = set([])\n",
    "for aut in authors:\n",
    "    if type(aut) == float:\n",
    "        continue\n",
    "    for au in aut.split('|'):\n",
    "        a.add(au)\n",
    "\n",
    "names = set([])\n",
    "for author in a:\n",
    "    for name in author.split(' '):\n",
    "        names.add(name)\n",
    "\n",
    "confNamePair = {}\n",
    "confTypePair = {}\n",
    "confType = ['workshop', 'symposium', 'expert_group', 'regular']\n",
    "for ID in confID: \n",
    "    confNamePair[ID] = f'{random.sample(names, k=1)[0]} {random.sample(names, k=1)[0]}'\n",
    "    confTypePair[ID] = random.sample(confType, k=1)[0]\n",
    "    \n",
    "def get_author(x):\n",
    "    return confNamePair[x]\n",
    "\n",
    "def get_type(x):\n",
    "    return confTypePair[x]\n",
    "\n",
    "proceeding['chair'] = proceeding['conferenceID'].apply(get_author)\n",
    "proceeding['conferenceType'] = proceeding['conferenceID'].apply(get_type)\n",
    "\n",
    "pro = set(proceeding['articleID'].unique())\n",
    "confPaperTypePair = {}\n",
    "confPaperTypes = ['poster', 'full_paper', 'demo_paper', 'short_paper']\n",
    "for artID in pro:\n",
    "    confPaperTypePair[artID] = random.sample(confPaperTypes, k=1)[0]\n",
    "    \n",
    "def get_paper_type(x):\n",
    "    return confPaperTypePair[x]\n",
    "\n",
    "proceeding['articleType'] = proceeding['articleID'].apply(get_paper_type)\n",
    "\n",
    "proceeding['reviews'] = proceeding['reviewed_by'].apply(generate_reviews)\n",
    "proceeding['decisions'] = proceeding['reviewed_by'].apply(generate_decisions)\n",
    "proceeding['decisionID'] = proceeding.apply(lambda x: generate_decisionIDs(x.articleID, x.reviewed_by), axis=1)\n",
    "\n",
    "proceeding['author'] = proceeding['author'].apply(replace_null_authors)\n",
    "\n",
    "proceeding['author'] = proceeding['author'].apply(clean_instances)\n",
    "proceeding['conference'] = proceeding['conference'].apply(clean_instances)\n",
    "proceeding['reviewed_by'] = proceeding['reviewed_by'].apply(clean_instances)\n",
    "proceeding['chair'] = proceeding['chair'].apply(clean_instances)\n",
    "proceeding['topic'] = proceeding['topic'].apply(clean_instances)\n",
    "\n",
    "proceeding['topic'] = proceeding['topic'].apply(replace_capitals)\n",
    "\n",
    "proceeding = proceeding.drop(['volume',\n",
    "                                 'url', \n",
    "                                 'author-orcid',\n",
    "                                 'ee-type', \n",
    "                                 'pages', \n",
    "                                 'inprocmdate', \n",
    "                                 'author-orcid', \n",
    "                                 'abstract', \n",
    "                                 'co_authors',\n",
    "                                 'citations',\n",
    "                                 'isbn',\n",
    "                                 'series',\n",
    "                                 'publisher',\n",
    "                                 'doi',\n",
    "                                 'crossref',\n",
    "                                 'key',\n",
    "                                 'procee',\n",
    "                                 'corresponding', \n",
    "                                 'procmdate', \n",
    "                                 'year'], 1)\n",
    "\n",
    "proceeding.to_csv('proceeding_processed.csv')\n",
    "proceeding[:5].to_csv('proceeding_slice.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da4d7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles.rename(columns = {'keywords': 'topics'})\n",
    "\n",
    "articles['journalID'] = articles.groupby(by=['journal', 'volume']).ngroup().add(1)\n",
    "jourID = articles['journalID'].unique()\n",
    "authors = articles['author'].unique()\n",
    "\n",
    "a = set([])\n",
    "for aut in authors:\n",
    "    if type(aut) == float:\n",
    "        continue\n",
    "    for au in aut.split('|'):\n",
    "        a.add(au)\n",
    "\n",
    "names = set([])\n",
    "for author in a:\n",
    "    for name in author.split(' '):\n",
    "        names.add(name)\n",
    "        \n",
    "jourNamePair = {}\n",
    "for ID in jourID:\n",
    "    jourNamePair[ID] = f'{random.sample(names, k=1)[0]} {random.sample(names, k=1)[0]}'\n",
    "\n",
    "def get_author(x):\n",
    "    return jourNamePair[x]\n",
    "\n",
    "articles['editor'] = articles['journalID'].apply(get_author)    \n",
    "\n",
    "\n",
    "art = set(articles['article'].unique())\n",
    "    \n",
    "jourPaperTypePair = {}\n",
    "\n",
    "jourPaperTypes = ['full_paper', 'demo_paper', 'short_paper']\n",
    "for artID in art:\n",
    "    jourPaperTypePair[artID] = random.sample(jourPaperTypes, k=1)[0]\n",
    "\n",
    "def get_paper_type(x):\n",
    "    return jourPaperTypePair[x]    \n",
    "\n",
    "articles['paperType'] = articles['article'].apply(get_paper_type)\n",
    "\n",
    "articles['reviews'] = articles['reviewed_by'].apply(generate_reviews)\n",
    "articles['decisions'] = articles['reviewed_by'].apply(generate_decisions)\n",
    "articles['decisionID'] = articles.apply(lambda x: generate_decisionIDs(x.article, x.reviewed_by), axis=1)\n",
    "\n",
    "articles['author'] = articles['author'].apply(replace_null_authors)\n",
    "articles['topics'] = articles['topics'].apply(replace_null_topics)\n",
    "\n",
    "articles['author'] = articles['author'].apply(clean_instances)\n",
    "articles['journal'] = articles['journal'].apply(clean_instances)\n",
    "articles['reviewed_by'] = articles['reviewed_by'].apply(clean_instances)\n",
    "articles['editor'] = articles['editor'].apply(clean_instances)\n",
    "articles['topics'] = articles['topics'].apply(clean_instances)\n",
    "\n",
    "articles['topics'] = articles['topics'].apply(replace_capitals)\n",
    "\n",
    "\n",
    "articles = articles.drop(['key',\n",
    "                          'author-orcid',\n",
    "                          'ee',\n",
    "                          'ee-type',\n",
    "                          'pages',\n",
    "                          'publtype',\n",
    "                          'abstract',\n",
    "                          'citations',\n",
    "                          'url',\n",
    "                          'key',\n",
    "                          'corresponding',\n",
    "                          'co_authors',\n",
    "                          'correspondingID',\n",
    "                          'mdate', \n",
    "                          'year'],1)\n",
    "\n",
    "articles.to_csv('articles_processed.csv')\n",
    "articles[:5].to_csv('article_slice.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af4db3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for top in articles['topics']:\n",
    "    if \"\\n\" in top:\n",
    "        print(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62028743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8781734c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
